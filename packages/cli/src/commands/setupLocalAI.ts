/**
 * @license
 * Copyright 2025 Hayate Esaki
 * SPDX-License-Identifier: Apache-2.0
 */
import {
  checkOllamaInstallation,
  getOllamaInstallInstructions,
  startOllamaService,
  installOllamaModel,
  // getInstalledModels, // Currently unused
} from '../utils/ollamaSetup.js';
import {
  checkHuggingFaceSetup,
  _getPythonSetupInstructions,
  // _getDockerSetupInstructions, // Currently unused
  getRecommendedHFModels,
  // _validateHuggingFaceAPIKey, // Currently unused
} from '../utils/huggingfaceSetup.js';

export interface SetupCommandOptions {
  provider: 'ollama' | 'huggingface' | 'all';
  install?: boolean;
  start?: boolean;
  model?: string;
  check?: boolean;
  interactive?: boolean;
}

/**
 * ãƒ­ãƒ¼ã‚«ãƒ«AIã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚³ãƒãƒ³ãƒ‰
 */
export async function setupLocalAI(options: SetupCommandOptions): Promise<void> {
  const { provider, install, start, model, check, interactive } = options;

  console.log('ğŸ¤– ãƒ­ãƒ¼ã‚«ãƒ«AI ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n');

  if (provider === 'ollama' || provider === 'all') {
    await setupOllama({ install, start, model, check, interactive });
  }

  if (provider === 'huggingface' || provider === 'all') {
    await setupHuggingFace({ check, interactive });
  }
}

/**
 * Ollamaã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
 */
async function setupOllama(options: {
  install?: boolean;
  start?: boolean;
  model?: string;
  check?: boolean;
  interactive?: boolean;
}): Promise<void> {
  console.log('ğŸ¦™ Ollama ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n');

  const status = await checkOllamaInstallation();

  if (options.check) {
    displayOllamaStatus(status);
    return;
  }

  if (!status.isInstalled) {
    console.log('âŒ OllamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“\n');
    console.log(getOllamaInstallInstructions());
    
    if (options.interactive) {
      console.log('\nâ³ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†å¾Œã€å†åº¦ã“ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„');
    }
    return;
  }

  console.log('âœ… Ollama ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿');
  if (status.version) {
    console.log(`ğŸ“¦ ãƒãƒ¼ã‚¸ãƒ§ãƒ³: ${status.version}`);
  }

  if (!status.isRunning) {
    console.log('âš ï¸  OllamaãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“');
    
    if (options.start || options.interactive) {
      console.log('ğŸš€ Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’é–‹å§‹ä¸­...');
      const started = await startOllamaService();
      
      if (started) {
        console.log('âœ… Ollamaã‚µãƒ¼ãƒ“ã‚¹ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸ');
        // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å†ç¢ºèª
        const newStatus = await checkOllamaInstallation();
        if (newStatus.isRunning) {
          status.isRunning = true;
          status.installedModels = newStatus.installedModels;
        }
      } else {
        console.log('âŒ Ollamaã‚µãƒ¼ãƒ“ã‚¹ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.log('æ‰‹å‹•ã§é–‹å§‹ã—ã¦ãã ã•ã„: ollama serve');
        return;
      }
    } else {
      console.log('æ‰‹å‹•ã§é–‹å§‹ã—ã¦ãã ã•ã„: ollama serve');
      return;
    }
  } else {
    console.log('âœ… Ollama å®Ÿè¡Œä¸­');
  }

  // ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
  console.log(`\nğŸ“š ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: ${status.installedModels.length}å€‹`);
  if (status.installedModels.length > 0) {
    status.installedModels.forEach(modelName => {
      console.log(`  â€¢ ${modelName}`);
    });
  }

  // ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
  if (options.model) {
    if (!status.installedModels.includes(options.model)) {
      console.log(`\nâ¬‡ï¸  ãƒ¢ãƒ‡ãƒ« ${options.model} ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...`);
      const success = await installOllamaModel(options.model, (progress) => {
        if (progress.status === 'downloading') {
          process.stdout.write(`\ré€²è¡ŒçŠ¶æ³: ${progress.progress || 0}%`);
        } else if (progress.status === 'completed') {
          console.log('\nâœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†');
        } else if (progress.status === 'error') {
          console.log(`\nâŒ ã‚¨ãƒ©ãƒ¼: ${progress.error}`);
        }
      });

      if (!success) {
        console.log('âŒ ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ');
        return;
      }
    } else {
      console.log(`âœ… ãƒ¢ãƒ‡ãƒ« ${options.model} ã¯æ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ã™`);
    }
  } else if (status.installedModels.length === 0) {
    console.log('\nğŸ’¡ æ¨å¥¨: æœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„');
    console.log('ä¾‹: enfiy setup ollama --model llama3.2:3b');
    
    status.recommendedModels.forEach(model => {
      console.log(`  â€¢ ${model.name} (${model.size}) - ${model.description}`);
    });
  }

  console.log('\nğŸ‰ Ollama ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼');
}

/**
 * HuggingFaceã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
 */
async function setupHuggingFace(options: {
  check?: boolean;
  interactive?: boolean;
}): Promise<void> {
  console.log('ğŸ¤— HuggingFace ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n');

  const status = await checkHuggingFaceSetup();

  if (options.check) {
    displayHuggingFaceStatus(status);
    return;
  }

  console.log('ğŸ“‹ HuggingFace ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³:\n');

  console.log('1ï¸âƒ£ ã‚¯ãƒ©ã‚¦ãƒ‰APIï¼ˆæ¨å¥¨ï¼‰:');
  console.log('   â€¢ https://huggingface.co/settings/tokens ã§APIã‚­ãƒ¼ã‚’å–å¾—');
  console.log('   â€¢ CLIè¨­å®šã§APIã‚­ãƒ¼ã‚’å…¥åŠ›');
  console.log('   â€¢ è±Šå¯Œãªãƒ¢ãƒ‡ãƒ«ãŒå³åº§ã«åˆ©ç”¨å¯èƒ½');

  console.log('\n2ï¸âƒ£ ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ:');
  console.log('   â€¢ Pythonç’°å¢ƒã¾ãŸã¯DockerãŒå¿…è¦');
  console.log('   â€¢ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ»é«˜é€Ÿãƒ»ã‚ªãƒ•ãƒ©ã‚¤ãƒ³åˆ©ç”¨å¯èƒ½');

  if (!status.pythonInstalled) {
    console.log('\nâš ï¸  Pythonç’°å¢ƒãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ');
    console.log(_getPythonSetupInstructions());
  } else {
    console.log('\nâœ… Pythonç’°å¢ƒ: åˆ©ç”¨å¯èƒ½');
    
    if (!status.transformersInstalled) {
      console.log('âš ï¸  Transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«');
      console.log('ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install transformers torch');
    } else {
      console.log('âœ… Transformers: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿');
    }
  }

  if (status.localServerAvailable) {
    console.log(`âœ… ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼: ${status.localServerUrl} ã§å®Ÿè¡Œä¸­`);
  } else {
    console.log('âš ï¸  ãƒ­ãƒ¼ã‚«ãƒ«æ¨è«–ã‚µãƒ¼ãƒãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ');
    console.log('\nãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³:');
    status.recommendedServers.forEach(server => {
      console.log(`\nâ€¢ ${server.displayName} (${server.difficulty})`);
      console.log(`  ${server.description}`);
      console.log(`  è¦ä»¶: ${server.requirements.join(', ')}`);
      console.log(`  ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: ${server.installCommand}`);
    });
  }

  console.log('\nğŸ‰ HuggingFace ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰å®Œäº†ï¼');
  console.log('CLIè¨­å®šã§è©³ç´°ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’è¡Œãˆã¾ã™');
}

/**
 * Ollamaã®çŠ¶æ³ã‚’è¡¨ç¤º
 */
function displayOllamaStatus(status: {isInstalled: boolean, version?: string, isRunning: boolean, installedModels: string[], recommendedModels: Array<{name: string, size: string, description: string, isInstalled: boolean}>}): void {
  console.log('ğŸ¦™ Ollama ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹\n');
  
  console.log(`ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«çŠ¶æ³: ${status.isInstalled ? 'âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿' : 'âŒ æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«'}`);
  
  if (status.version) {
    console.log(`ãƒãƒ¼ã‚¸ãƒ§ãƒ³: ${status.version}`);
  }
  
  console.log(`ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³: ${status.isRunning ? 'âœ… å®Ÿè¡Œä¸­' : 'âŒ åœæ­¢ä¸­'}`);
  
  console.log(`ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: ${status.installedModels.length}å€‹`);
  if (status.installedModels.length > 0) {
    status.installedModels.forEach((model: string) => {
      console.log(`  â€¢ ${model}`);
    });
  }

  if (status.recommendedModels.length > 0) {
    console.log('\næ¨å¥¨ãƒ¢ãƒ‡ãƒ«:');
    status.recommendedModels.forEach((model: {name: string, size: string, description: string, isInstalled: boolean}) => {
      const icon = model.isInstalled ? 'âœ…' : 'â¬‡ï¸';
      console.log(`  ${icon} ${model.name} (${model.size}) - ${model.description}`);
    });
  }
}

/**
 * HuggingFaceã®çŠ¶æ³ã‚’è¡¨ç¤º
 */
function displayHuggingFaceStatus(status: {pythonInstalled: boolean, transformersInstalled: boolean, localServerAvailable: boolean, localServerUrl?: string, recommendedServers: Array<{name: string, requirements: string[], installCommand: string}>}): void {
  console.log('ğŸ¤— HuggingFace ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹\n');
  
  console.log(`Pythonç’°å¢ƒ: ${status.pythonInstalled ? 'âœ… åˆ©ç”¨å¯èƒ½' : 'âŒ æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«'}`);
  console.log(`Transformers: ${status.transformersInstalled ? 'âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿' : 'âŒ æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«'}`);
  console.log(`ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼: ${status.localServerAvailable ? `âœ… ${status.localServerUrl}` : 'âŒ æ¤œå‡ºã•ã‚Œãš'}`);

  if (status.recommendedServers.length > 0) {
    console.log('\nåˆ©ç”¨å¯èƒ½ãªãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³:');
    status.recommendedServers.forEach((server: {name: string, requirements: string[], installCommand: string}) => {
      console.log(`  â€¢ ${server.name}`);
      console.log(`    è¦ä»¶: ${server.requirements.join(', ')}`);
      console.log(`    ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: ${server.installCommand}`);
    });
  }

  const models = getRecommendedHFModels();
  console.log('\næ¨å¥¨ãƒ¢ãƒ‡ãƒ«:');
  models.forEach(model => {
    const compatibility = model.localCompatible ? 'ğŸ  ãƒ­ãƒ¼ã‚«ãƒ«å¯¾å¿œ' : 'â˜ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ã®ã¿';
    console.log(`  â€¢ ${model.displayName} (${model.size}) - ${compatibility}`);
    console.log(`    ${model.description}`);
  });
}

/**
 * ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚³ãƒãƒ³ãƒ‰ã®ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
 */
export function displaySetupHelp(): void {
  console.log('ğŸ¤– ãƒ­ãƒ¼ã‚«ãƒ«AI ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚³ãƒãƒ³ãƒ‰\n');
  
  console.log('ä½¿ç”¨æ³•:');
  console.log('  enfiy setup <provider> [options]\n');
  
  console.log('ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼:');
  console.log('  ollama       Ollamaã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—');
  console.log('  huggingface  HuggingFaceã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—');
  console.log('  all          ä¸¡æ–¹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n');
  
  console.log('ã‚ªãƒ—ã‚·ãƒ§ãƒ³:');
  console.log('  --check      ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª');
  console.log('  --install    è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è©¦è¡Œ');
  console.log('  --start      ã‚µãƒ¼ãƒ“ã‚¹ã‚’é–‹å§‹');
  console.log('  --model      æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«');
  console.log('  --interactive å¯¾è©±çš„ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n');
  
  console.log('ä¾‹:');
  console.log('  enfiy setup ollama --check');
  console.log('  enfiy setup ollama --start --model llama3.2:3b');
  console.log('  enfiy setup huggingface --check');
  console.log('  enfiy setup all --interactive');
}